{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696e11e7",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "This notebook explains linear regression models for the purpose of prediction. It discusses the differences between fitting and using regression models for the purpose of inference (as in classical statistics) and for prediction. A predictive goal calls for evaluating model performance on a validation set, and for using predictive metrics. It then raises the challenges of using many predictors and describes variable selection algorithms that are often implemented in linear regression procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e89764",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Imports required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78b5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dmutils.utils import regression_summary\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf194e7e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The most popular model for making predictions is the *multiple linear regression model* encountered in most introductory statistics courses and textbooks. This model is used to fit a relationship between a numerical *outcome variable Y* (also called the *response*, *target*, or *dependent variable*) and a set of *predictors* $X_1$, $X_2$, ..., $X_p$ (also referred to as *independent variables*, *input variables*, *regressors*, or *covariates*). The assumption is that the following function approximates the relationship between the predictors and outcome variable:\n",
    "\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        $Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\epsilon$\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "where $\\beta_0$, ..., $\\beta_p$ are *coefficients* and $\\epsilon$ is the *noise* or *unexplained* part. Data are then used to estimate the coefficients and to quantify the noise. In predictive modeling, the data are also used to evaluate model performance.\n",
    "\n",
    "Regression modeling means not only estimating the coefficients but also choosing which predictors to include and in what form. For example, a numerical predictor can be included as is, or in logarithmic form $[\\log (X)]$, or in a binned form (e.g., age group). Choosing the right form depends on domain knowledge, data availability, and needed predictive power.\n",
    "\n",
    "Multiple linear regression is applicable to numerous predictive modeling situations. Examples are predicting customer activity on credit cards from their demographics and historical activity patterns, predicting expenditures on vacation travel based on historical frequent flyer data, predicting staffing requirements at help desks based on historical data and product and sales information, predicting sales from cross-selling of products from historical information, and predicting the impact of discounts on sales in retail outlets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c92483",
   "metadata": {},
   "source": [
    "## Exploratory vs. Predictive modeling\n",
    "\n",
    "Before introducing the use of linear regression for prediction, one must clarify an important distinction that often escapes those with earlier familiarity with linear regression from courses in statistics. In particular, the two popular but different objectives behind fitting a regression model are:\n",
    "\n",
    "1. Explaining or quantifying the average effect of inputs on an outcome (explanatory or descriptive task, respectively)\n",
    "\n",
    "2. Predicting the outcome value for new records, given their input values (predictive task)\n",
    "\n",
    "The classical statistical approach is focused on the first objective. In that scenario, the data are treated as a random sample from a larger population of interest. The regression model estimated from this sample is an attempt to capture the *average* relationship in the larger population. This model is then used in decision-making to generate statements such as \"a unit increase in service speed ($X_1$) is associated with an average increase of 5 points in customer satisfaction ($Y$), all other factors ($X_2$, $X_3$, ..., $X_p$) being equal.\". If $X_1$ is known to cause $Y$, then such a statement indicates actionable policy changes - this is called explanatory modeling. When the causal structure is unknown, then this model quantifies the degree of* association* between the inputs and outcome variable, and the approach is called descriptive modeling.\n",
    "\n",
    "In predictive analytics, however, the focus is typically on the second goal: predicting new individual records. Here we are not interested in the coefficients themselves, nor in the \"average record\", but rather in the predictions that this model can generate for new records. In this scenario, the model is used for micro-decision-making at the record level. As a practical example, it could be used to predict customer satisfaction for each new customer of interest.\n",
    "\n",
    "Both explanatory and predictive modeling involve using a dataset to fit a model (i.e., to estimate coefficients), checking model validity, assessing its performance, and comparing to other models. However, the modeling steps and performance assessment differ in the two cases, usually leading to different final models. Therefore, the choice of model is closely tied to whether the goal is explanatory or predictive.\n",
    "\n",
    "In explanatory and descriptive modeling, where the focus is on modeling the average record, the attempt is to fit the best model to the data to learn about the underlying relationship in the population. In contrast, in predictive modeling (data mining), the goal is to find a regression model that best predicts new individual records. A regression model that fits the existing data too well is not likely to perform well with new data. Hence, we look for a model that has the highest predictive power by evaluating it on a holdout set and using predictive metrics.\n",
    "\n",
    "Let us summarize the main differences in using a linear regression in the two scenarios:\n",
    "\n",
    "1. A good explanatory model is one that fits the data closely, whereas a good predictive model is one that predicts new records accurately. Choices of input variables and their form can therefore differ.\n",
    "\n",
    "2. In explanatory models, the entire dataset is used for estimating the best-fit model, to maximize the amount of information that we have about the hypothesized relationship in the population. When the goal is to predict outcomes of new individual records, the data are typically split into a training set and a validation set. The training set is used to estimate the model, and the validation or *holdout set* is used to assess this model's predictive performance on new, unobserved data.\n",
    "\n",
    "3. Performance measures for explanatory models measure how close the data fit the model (how well the model approximates the data) and how strong the average relationship is, whereas in predictive models performance is measured by predictive accuracy (how well the model predicts new individual records).\n",
    "\n",
    "4. In explanatory models the focus is on the coefficients ($\\beta$), whereas in predictive models the focus is on the predictions ($\\hat{y}$).\n",
    "\n",
    "For these reasons, it is extremely important to know the goal of the analysis before beginning the modeling process. A good predictive model can have a looser fit to the data on which it is based, and a good explanatory model can have low prediction accuracy. Therefore, the remainder of this notebook focuses on predictive models because these are more popular in data mining and because most statistics textbooks focus on explanatory modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82937148",
   "metadata": {},
   "source": [
    "## Estimating the Regression Equation and Prediction\n",
    "\n",
    "Once determined the predictors to include and their form, we estimate the coefficients of the regression formula from the data using a method called *ordinary least squares* (OLS). This method finds values $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, ..., $\\hat{\\beta}_p$ that minimize the sum of squared deviations between the actual outcome values ($Y$) and their predicted values based on that model ($\\hat{Y}$).\n",
    "\n",
    "To predict the value of the outcome variable for a record with predictor values $x_1$, $x_2$, ..., $x_p$, we use the equation:\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        $\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + ... + \\hat{\\beta}_p x_p$\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "Predictions based on this equation are the best predictions possible in the sense that they will be unbiased (equal to the true values on average) and will have the smallest mean squared error compared to any unbiased estimates *if* we make the following assumptions:\n",
    "\n",
    "1. The noise $\\epsilon$ (or equivalently, $Y$) follows a normal distribution.\n",
    "\n",
    "2. The choice of predictors and their form is correct (*linearity*).\n",
    "\n",
    "3. The records are independent of each other.\n",
    "\n",
    "4. The variability in the outcome values for a given set of predictors is the same regardless of the values of the predictors (*homoskedasticity*).\n",
    "\n",
    "An important and interesting fact for the predictive goal is that *even if we drop the first assumption and allow the noise to follow an arbitrary distribution, these estimates are very good for prediction*, in the sense that among all linear models, as defined by equation above, the model using the least squares estimates, $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, ..., $\\hat{\\beta}_p$, will have the smallest mean squared errors. The assumption of a normal distribution is required in explanatory modeling, where it is used for constructing confidence intervals and statistical tests for the model parameters.\n",
    "\n",
    "Even if the other assumptions are violated, it is still possible that the resulting predictions are sufficiently accurate and precise for the purpose they are intended for. The key is to evaluate predictive performance of the model, which is the main priority. Satisfying assumptions is of secondary interest and residual analysis can give clues to potential improved models to examine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fbb641",
   "metadata": {},
   "source": [
    "### Example: Predicting the Price of Used Toyota Corolla Cars\n",
    "\n",
    "A large Toyota car dealership offers purchasers of new Toyota cars the option to buy their used car as part of a trade-in. In particular, a new promotion promises to pay high prices for used Toyota Corolla cars for purchasers of a new car. The dealer then sells the used cars for a small profit. To ensure a reasonable profit, the dealer needs to be able to predict the price that the dealership will get for the used cars. For that reason, data were collected on all previous sales of used Toyota Corollas at the dealership. The data include the sales price and other information on the car, such as its age, mileage, fuel type, and engine size. A description of each of these variables is given below:\n",
    "\n",
    "\n",
    "    Price: Offer price in Euros\n",
    "    Age: Age in months as of August 2004\n",
    "    Kilometers: Accumulated kilometers on odometer\n",
    "    Fuel type: Fuel type (Petrol, Diesel, CNG)\n",
    "    HP: Horsepower\n",
    "    Metallic: Metallic color? (Yes = 1, No = 0)\n",
    "    Automatic: Automatic (Yes = 1, No = 0)\n",
    "    CC: Cylinder volume in cubic centimeters\n",
    "    Doors: Number of doors\n",
    "    QuartTax: Quarterly road tax in Euros\n",
    "    Weight: Weight in kilograms\n",
    "\n",
    "A sample of this dataset is shown below. The total number of records in the dataset is 1000 cars (we use the first 1000 cars from the dataset `ToyotoCorolla.csv`).After partitioning the data into training (60%) and validation\n",
    "(40%) sets, we fit a multiple linear regression model between price (the outcome variable) and the other variables (as predictors) using only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96259917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Parking_Assistant</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Model  Price  Age_08_04  \\\n",
       "0   1  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1   2  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "2   3  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950         24   \n",
       "3   4  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950         26   \n",
       "4   5    TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750         30   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type  HP  Met_Color  ... Powered_Windows  \\\n",
       "0         10      2002  46986    Diesel  90          1  ...               1   \n",
       "1         10      2002  72937    Diesel  90          1  ...               0   \n",
       "2          9      2002  41711    Diesel  90          1  ...               0   \n",
       "3          7      2002  48000    Diesel  90          0  ...               0   \n",
       "4          3      2002  38500    Diesel  90          0  ...               1   \n",
       "\n",
       "   Power_Steering  Radio  Mistlamps  Sport_Model  Backseat_Divider  \\\n",
       "0               1      0          0            0                 1   \n",
       "1               1      0          0            0                 1   \n",
       "2               1      0          0            0                 1   \n",
       "3               1      0          0            0                 1   \n",
       "4               1      0          1            0                 1   \n",
       "\n",
       "   Metallic_Rim  Radio_cassette  Parking_Assistant  Tow_Bar  \n",
       "0             0               0                  0        0  \n",
       "1             0               0                  0        0  \n",
       "2             0               0                  0        0  \n",
       "3             0               0                  0        0  \n",
       "4             0               0                  0        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce data frame to the top 1000 rows and select columns for regression analysis\n",
    "car_df = pd.read_csv(\"../datasets/ToyotaCorolla.csv\")\n",
    "car_df = car_df.iloc[0:1000]\n",
    "\n",
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35604dc",
   "metadata": {},
   "source": [
    "Below are the coefficients of the Multiple Linear Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb8ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Predictor  coefficient\n",
      "0          Age_08_04  -140.748761\n",
      "1                 KM    -0.017840\n",
      "2                 HP    36.103419\n",
      "3          Met_Color    84.281830\n",
      "4          Automatic   416.781954\n",
      "5                 CC     0.017737\n",
      "6              Doors   -50.657863\n",
      "7      Quarterly_Tax    13.625325\n",
      "8             Weight    13.038711\n",
      "9   Fuel_Type_Diesel  1066.464681\n",
      "10  Fuel_Type_Petrol  2310.249543\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0000\n",
      "       Root Mean Squared Error (RMSE) : 1400.5823\n",
      "            Mean Absolute Error (MAE) : 1046.9072\n",
      "          Mean Percentage Error (MPE) : -1.0223\n",
      "Mean Absolute Percentage Error (MAPE) : 9.2994\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Age_08_04\", \"KM\", \"Fuel_Type\", \"HP\", \"Met_Color\", \"Automatic\", \"CC\",\n",
    "              \"Doors\", \"Quarterly_Tax\", \"Weight\"]\n",
    "outcome = \"Price\"\n",
    "\n",
    "# partition data\n",
    "X = pd.get_dummies(car_df[predictors], drop_first=True)\n",
    "y = car_df[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, \n",
    "                                                      test_size=0.4,\n",
    "                                                      random_state=1)\n",
    "car_lmr = LinearRegression()\n",
    "car_lmr.fit(train_X, train_y)\n",
    "\n",
    "# print coefficients\n",
    "print(pd.DataFrame({'Predictor': X.columns, 'coefficient': car_lmr.coef_}))\n",
    "# print performance measures (training data)\n",
    "regression_summary(train_y, car_lmr.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50c415",
   "metadata": {},
   "source": [
    "Notice that the Fuel Type predictor has three categories (Petrol, Diesel, and CNG). We therefore have two dummy variables in the model: Fuel_Type_Petrol (0/1) and Fuel_Type_Diesel (0/1); the third, for CNG (0/1), is redundant given the information on the first two dummies. Including the redundant dummy would cause the regression to fail, since the redundant dummy will be a perfect linear combination of the other two.\n",
    "\n",
    "The regression coefficients are then used to predict prices of individual used Toyota Corolla cars based on their age, mileage, and so on. Below is a sample of predicted prices for 20 cars in the validation set, using the estimated model. It gives the predictions and their errors (relative to the actual prices) for these 20 cars. Below the predictions, we have overall measures of predictive accuracy. Note that the mean\n",
    "error (ME) is \\\\$104 and RMSE = \\\\$1,313."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93667c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted  Actual     Residual\n",
      "507  10607.333940   11500   892.666060\n",
      "818   9272.705792    8950  -322.705792\n",
      "452  10617.947808   11450   832.052192\n",
      "368  13600.396275   11450 -2150.396275\n",
      "242  12396.694660   11950  -446.694660\n",
      "929   9496.498212    9995   498.501788\n",
      "262  12480.063217   13500  1019.936783\n",
      "810   8834.146068    7950  -884.146068\n",
      "318  12183.361282    9900 -2283.361282\n",
      "49   19206.965683   21950  2743.034317\n",
      "446  10987.498309   11950   962.501691\n",
      "142  18501.527375   19950  1448.472625\n",
      "968   9914.690947    9950    35.309053\n",
      "345  13827.299932   14950  1122.700068\n",
      "971   7966.732543   10495  2528.267457\n",
      "133  17185.242041   15950 -1235.242041\n",
      "104  19952.658062   19450  -502.658062\n",
      "6    16570.609280   16900   329.390720\n",
      "600  13739.409113   11250 -2489.409113\n",
      "496  11267.513740   11750   482.486260\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 103.6803\n",
      "       Root Mean Squared Error (RMSE) : 1312.8523\n",
      "            Mean Absolute Error (MAE) : 1017.5972\n",
      "          Mean Percentage Error (MPE) : -0.2633\n",
      "Mean Absolute Percentage Error (MAPE) : 9.0111\n"
     ]
    }
   ],
   "source": [
    "# Use predict() to make predictions on a new set\n",
    "car_lmr_pred = car_lmr.predict(valid_X)\n",
    "result = pd.DataFrame({\"Predicted\": car_lmr_pred,\n",
    "                       \"Actual\": valid_y,\n",
    "                       \"Residual\": valid_y - car_lmr_pred})\n",
    "print(result.head(20))\n",
    "# print performance measures (validation data)\n",
    "regression_summary(valid_y, car_lmr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9db98",
   "metadata": {},
   "source": [
    "A histogram of the residuals shows that most of the errors are between ± \\\\$2000. This error magnitude might be small relative to the car price, but should be taken into account when considering the profit. Another observation of interest is the large positive residuals (under-predictions), which may or may not be a concern, depending on the application. Measures such as the mean error, and error percentiles are used to assess the predictive performance of a model and to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8c33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of datapoints with a residual in [-1406, 1406]:  0.7425\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_residuals = valid_y - car_lmr_pred\n",
    "\n",
    "# Determine the percentage of datapoints with a residual in [-1406, 1406] = approx. 75%\n",
    "print(\"Percentage of datapoints with a residual in [-1406, 1406]: \",\n",
    "      len(all_residuals[(all_residuals > -1406) & (all_residuals < 1406)]) / len(all_residuals))\n",
    "\n",
    "pd.DataFrame({\"Residuals\": all_residuals}).hist(bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fc2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
