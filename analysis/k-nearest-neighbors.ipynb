{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2de6c9e",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (k-NN)\n",
    "\n",
    "In this chapter, we describe the k-nearest-neighbors algorithm that can be used for classification (of a categorical outcome) or prediction (of a numerical outcome). To classify or predict a new record, the method relies on finding \"similar\" records in the training data. These \"neighbors\" are then used to derive a classification or prediction for the new record by voting (for classification) or averaging (for prediction). We explain how similarity is determined, how the number of neighbors is chosen, and how a classification or prediction is computed. k-NN is a highly automated data-driven method. We discuss the advantages and weaknesses of the k-NN method in terms of performance and practical considerations such as computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcf232",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Imports required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4819a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c671cc9",
   "metadata": {},
   "source": [
    "## The k-NN Classifier (Categorical Outcome)\n",
    "\n",
    "The idea in *k*-nearest-neighbors methods is to identify *k* records in the training dataset that are similar to a new record that we wish to classify. We then use these similar (neighboring) records to classify the new record into a class, assigning the new record to the predominant class among these neighbors. Denote the values of the predictors for this new record by $x_1$, $x_2$, ..., $x_p$. We look for records in our training data that are similar or \"near\" the record to be classified in the predictor space (i.e., records that have values close to $x_1$, $x_2$, ..., $x_p$). Then, based on the classes to which those proximate records belong, we assign a class to the record that we want to classify.\n",
    "\n",
    "### Determining Neighbors\n",
    "\n",
    "The k-nearest-neighbors algorithm is a classification method that does not make assumptions about the form of the relationship between the class membership (*Y*) and the predictors $X_1$, $X_2$, ..., $X_p$. This is a nonparametric method because it does not involve estimation of parameters in an assumed function form, such as the linear form assumed in [linear regression](./multiple-linear-regression.ipynb). Instead, this method draws information from similarities between the predictor values of the records in the dataset.\n",
    "\n",
    "A central question is how to measure the distance between records based on their predictor values. The most popular measure of distance is the Euclidean distance. The Euclidean distance between two records ($x_1$, $x_2$, ..., $x_p$) and ($u_1$, $u_2$, ..., $u_p$) is:\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        $\\sqrt{(x_1 - u_1)^2 + (x_2 - u_2)^2 + ... + (x_p - u_p)^2}$\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "You will find a host of other distance metrics elsewhere, for both numerical and categorical variables. However, the *k*-NN algorithm relies on many distance computations (between each record to be predicted and every record in the training set), and therefore the Euclidean distance, which is computationally cheap, is the most popular in *k*-NN.\n",
    "\n",
    "To equalize the scales that the various predictors may have, note that in most cases, predictors should first be standardized before computing a Euclidean distance. Also note that the means and standard deviations used to standardize new records are those of the *training* data, and the new record is not included in calculating them. The validation data, like new data, are also not included in this calculation.\n",
    "\n",
    "### Classification Rule\n",
    "\n",
    "After computing the distances between the record to be classified and existing records, we need a rule to assign a class to the record to be classified, based on the classes of its neighbors. The simplest case is *k* = 1, where we look for the record that is closest (the nearest neighbor) and classify the new record as belonging to the same class as its closest neighbor. It is a remarkable fact that this simple, intuitive idea of using a single nearest neighbor to classify records can be very powerful when we have a large number of records in our training set. It turns out that the misclassification error of the 1-nearest neighbor scheme has a misclassification rate that is no more than twice the error when we know exactly the probability density functions for each class.\n",
    "\n",
    "The idea of the *1-nearest neighbor* can be extended to *k* > 1 neighbors as follows:\n",
    "\n",
    "1. Find the nearest *k* neighbors to the record to be classified.\n",
    "\n",
    "2. Use a majority decision rule to classify the record, where the record is classified as a member of the majority class of the *k* neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdae4a",
   "metadata": {},
   "source": [
    "## Example: Riding Mowers\n",
    "\n",
    "A riding-mower manufacturer would like to find a way of classifying families in a city into those likely to purchase a riding mower and those not likely to buy one. A pilot random sample is undertaken of 12 owners and 12 nonowners in the city. The data are shown below. We first partition the data into training data (14 households) and validation data (10 households). Obviously, this dataset is too small for partitioning, which can result in unstable results, but we will continue with this partitioning for illustration purposes. A scatter plot of the training data is also shown below.\n",
    "\n",
    "Now consider a new household with \\\\$60,000 income and lot size 20,000 ft² (star marker on the figure). Among the households in the training set, the one closest to the new household (in Euclidean distance after normalizing income and lot size) is household 4, with \\\\$61,500 income and lot size 20,800 ft² . If we use a 1-NN classifier, we would classify the new household as an owner, like household 4. If we use *k* = 3, the three nearest households are 4,\n",
    "14, and 1, as can be seen visually in the scatter plot, and as computed by the software. Two of these neighbors are owners of riding mowers, and one is a nonowner. The majority vote is therefore *owner*, and the new household would be classified as an owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f168b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Lot_Size</th>\n",
       "      <th>Ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.5</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>82.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>84.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>49.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>66.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47.4</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>51.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>63.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>Nonowner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Lot_Size Ownership\n",
       "0     60.0      18.4     Owner\n",
       "1     85.5      16.8     Owner\n",
       "2     64.8      21.6     Owner\n",
       "3     61.5      20.8     Owner\n",
       "4     87.0      23.6     Owner\n",
       "5    110.1      19.2     Owner\n",
       "6    108.0      17.6     Owner\n",
       "7     82.8      22.4     Owner\n",
       "8     69.0      20.0     Owner\n",
       "9     93.0      20.8     Owner\n",
       "10    51.0      22.0     Owner\n",
       "11    81.0      20.0     Owner\n",
       "12    75.0      19.6  Nonowner\n",
       "13    52.8      20.8  Nonowner\n",
       "14    64.8      17.2  Nonowner\n",
       "15    43.2      20.4  Nonowner\n",
       "16    84.0      17.6  Nonowner\n",
       "17    49.2      17.6  Nonowner\n",
       "18    59.4      16.0  Nonowner\n",
       "19    66.0      18.4  Nonowner\n",
       "20    47.4      16.4  Nonowner\n",
       "21    33.0      18.8  Nonowner\n",
       "22    51.0      14.0  Nonowner\n",
       "23    63.0      14.8  Nonowner\n",
       "0     60.0      20.0         ?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mower_df = pd.read_csv(\"../datasets/RidingMowers.csv\")\n",
    "mower_df[\"Number\"] = mower_df.index + 1\n",
    "\n",
    "## new household\n",
    "new_household = pd.DataFrame({\"Income\": [60], \"Lot_Size\": [20],\n",
    "                              \"Number\": [25], \"Ownership\": [\"?\"]})\n",
    "\n",
    "pd.concat([mower_df, new_household])[[\"Income\", \"Lot_Size\", \"Ownership\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b3a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, valid_data = train_test_split(mower_df, test_size=0.4,\n",
    "                                          random_state=26)\n",
    "## scatter plot\n",
    "def plot_dataset(ax, data, show_label=True, **kwargs):\n",
    "    subset = data.loc[data[\"Ownership\"]==\"Owner\"]\n",
    "    ax.scatter(subset.Income, subset.Lot_Size, marker=\"o\",\n",
    "               label=\"Owner\" if show_label else None, color=\"C1\", **kwargs)\n",
    "    subset = data.loc[data[\"Ownership\"]==\"Nonowner\"]\n",
    "    ax.scatter(subset.Income, subset.Lot_Size, marker=\"D\",\n",
    "               label=\"Nonowner\" if show_label else None, color=\"C0\", **kwargs)\n",
    "    plt.xlabel(\"Income\") # set x-axis label\n",
    "    plt.ylabel(\"Lot_Size\") # set y-axis label\n",
    "    for _, row in data.iterrows():\n",
    "        ax.annotate(row.Number, (row.Income + 2, row.Lot_Size))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_dataset(ax, train_data)\n",
    "plot_dataset(ax, valid_data, show_label=False, facecolors=\"none\")\n",
    "ax.scatter(new_household.Income, new_household.Lot_Size, marker=\"*\",\n",
    "           label=\"New household\", color=\"black\", s=150)\n",
    "plt.xlabel(\"Income\"); plt.ylabel(\"Lot_Size\")\n",
    "ax.set_xlim(40, 115)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce25e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zIncome</th>\n",
       "      <th>zLot_Size</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.409776</td>\n",
       "      <td>0.743358</td>\n",
       "      <td>Owner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.804953</td>\n",
       "      <td>0.743358</td>\n",
       "      <td>Nonowner</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.477910</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>Owner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zIncome  zLot_Size Ownership  Number\n",
       "3  -0.409776   0.743358     Owner       4\n",
       "13 -0.804953   0.743358  Nonowner      14\n",
       "0  -0.477910  -0.174908     Owner       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize normalized training, validation, and complete data frames\n",
    "# use the training data to learn the transformation.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data[[\"Income\", \"Lot_Size\"]]) # Note the use of array of column names\n",
    "\n",
    "# transform the full dataset\n",
    "mower_norm = pd.concat([pd.DataFrame(scaler.transform(mower_df[[\"Income\", \"Lot_Size\"]]),\n",
    "                                     columns=[\"zIncome\", \"zLot_Size\"]),\n",
    "                        mower_df[[\"Ownership\", \"Number\"]]], axis=1)\n",
    "\n",
    "train_norm = mower_norm.iloc[train_data.index]\n",
    "valid_norm = mower_norm.iloc[valid_data.index]\n",
    "\n",
    "## new household\n",
    "new_household = pd.DataFrame({\"Income\": [60], \"Lot_Size\": [20]})\n",
    "new_household_norm = pd.DataFrame(scaler.transform(new_household),\n",
    "                                  columns=[\"zIncome\", \"zLog_Size\"])\n",
    "\n",
    "# user NearestNeighbors from scikit-learn to compute knn\n",
    "knn = NearestNeighbors(n_neighbors=3)\n",
    "knn.fit(train_norm.iloc[:, 0:2])\n",
    "distances, indices = knn.kneighbors(new_household_norm)\n",
    "\n",
    "# indices is a list of lists, we are only interested in the first element\n",
    "train_norm.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9f9cf",
   "metadata": {},
   "source": [
    "### Choosing k\n",
    "\n",
    "The advantage of choosing *k* > 1 is that higher values of *k* provide smoothing that reduces the risk of overfitting due to noise in the training data. Generally speaking, if *k* is too low, we may be fitting to the noise in the data. However, if *k* is too high, we will miss out on the method's ability to capture the local structure in the data, one of its main advantages. In the extreme, *k* = *n* = the number of records in the training dataset. In that case, we simply assign all records to the majority class in the training data,irrespective of the values of ($x_1$, $x_2$, ...,$x_p$), which coincides with the naive rule! This is clearly a case of oversmoothing in the absence of useful information in the predictors about the class membership. In other words, we want to balance between overfitting to the predictor information and ignoring this information completely. A balanced choice greatly depends on the nature of the data. The more complex and irregular the structure of the data, the lower the optimum value of *k*. Typically, values of *k* fall in the range of 1-20. We will use odd numbers to avoid ties.\n",
    "\n",
    "So how is *k* chosen? Answer: We choose the *k* with the best classification performance. We use the training data to classify the records in the validation data, then compute error rates for various choices of *k*. For our example, if we choose *k* = 1, we will classify in a way that is very sensitive to the local characteristics of the training data. On the other hand, if we choose a large value of *k*, such as *k* = 14, we would simply predict the most frequent class in the dataset in all cases. This is a very stable prediction but it completely ignores the information in the predictors. To find a balance, we examine the accuracy (of predictions in the validation set) that results from different choices of *k* between 1 and 14. For an even number *k*, if there is a tie in classifying a household, the tie is broken randomly. This is shown in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9417582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy\n",
       "0    1       0.6\n",
       "1    2       0.7\n",
       "2    3       0.8\n",
       "3    4       0.9\n",
       "4    5       0.7\n",
       "5    6       0.9\n",
       "6    7       0.9\n",
       "7    8       0.9\n",
       "8    9       0.9\n",
       "9   10       0.8\n",
       "10  11       0.8\n",
       "11  12       0.9\n",
       "12  13       0.4\n",
       "13  14       0.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_norm[[\"zIncome\", \"zLot_Size\"]]\n",
    "train_y = train_norm[\"Ownership\"]\n",
    "valid_X = valid_norm[[\"zIncome\", \"zLot_Size\"]]\n",
    "valid_y = valid_norm[\"Ownership\"]\n",
    "\n",
    "# Train a classifier for different values of k\n",
    "results = []\n",
    "for k in range(1, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k).fit(train_X, train_y)\n",
    "    results.append({\"k\": k,\n",
    "                    \"accuracy\": accuracy_score(valid_y, knn.predict(valid_X))})\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20cf9a",
   "metadata": {},
   "source": [
    "Best *k* is 4!\n",
    "\n",
    "Once *k* is chosen, we rerun the algorithm on the combined training and testing sets in order to generate classifications of new records. An example is shown below, where the four nearest neighbors are used to classify the new household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7b86f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ownership: ['Owner']\n",
      "Distances: [[0.31358009 0.40880312 0.44793643 0.61217726]]\n",
      "Indices: [[ 3  8 13  0]]\n",
      "     zIncome  zLot_Size Ownership  Number\n",
      "3  -0.409776   0.743358     Owner       4\n",
      "8  -0.069107   0.437269     Owner       9\n",
      "13 -0.804953   0.743358  Nonowner      14\n",
      "0  -0.477910  -0.174908     Owner       1\n"
     ]
    }
   ],
   "source": [
    "# Retrain with full dataset\n",
    "mower_X = mower_norm[[\"zIncome\", \"zLot_Size\"]]\n",
    "mower_y = mower_norm[\"Ownership\"]\n",
    "knn = KNeighborsClassifier(n_neighbors=4).fit(mower_X, mower_y)\n",
    "\n",
    "distances, indices = knn.kneighbors(new_household_norm)\n",
    "print(\"Predicted Ownership:\", knn.predict(new_household_norm))\n",
    "print(\"Distances:\", distances)\n",
    "print(\"Indices:\", indices)\n",
    "print(mower_norm.iloc[indices[0], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7daa22a",
   "metadata": {},
   "source": [
    "### Setting the Cutoff Value\n",
    "\n",
    "*k*-NN uses a majority decision rule to classify a new record, where the record is classified as a member of the majority class of the *k* neighbors. The definition of \"majority\" is directly linked to the notion of a cutoff value applied to the class membership probabilities. Let us consider a binary outcome case.For a new record, the proportion of class 1 members among its neighbors is an estimate of its propensity (probability) of belonging to class 1. In the riding mowers example with *k* = 4, we found that the four nearest neighbors to the new household (with income = \\\\$60,000 and lot size = 20,000 ft²) are households 4, 9, 14, and 1.\n",
    "\n",
    "Since three of these are owners and one is a nonowner, we can estimate for the new household a probability of 0.75 of being an owner (and 0.25 for being a nonowner). Using a simple majority rule is equivalent to setting the cutoff value to 0.5. In the above results, we see that the software assigned class *owner* to this record.\n",
    "\n",
    "As mentioned in [Evaluating Prediction Performance](./evaluating-predictive-performance.ipynb), changing the cutoff value affects the confusion matrix (i.e., the error rates). Hence, in some cases we might want to choose a cutoff other than the default 0.5 for the purpose of maximizing accuracy or for incorporating misclassification costs.\n",
    "\n",
    "### k-NN with More Than Two Classes\n",
    "\n",
    "The k-NN classifier can easily be applied to an outcome with *m* classes, where *m* > 2. The \"majority rule\" means that a new record is classified as a member of the majority class of its *k* neighbors. An alternative, when there is a specific class that we are interested in identifying (and are willing to \"overidentify\" records as belonging to this class), is to calculate the proportion of the *k* neighbors that belong to this class of interest, use that as an estimate of the probability (propensity) that the new record belongs to that class, and then refer to a user-specified cutoff value to decide whether to assign the new record to that class. For more on the use of cutoff value in classification where there is a single class of interest, see [Evaluating Prediction Performance](./evaluating-predictive-performance.ipynb)\n",
    "\n",
    "### Converting Categorical Variables to Binary Dummies\n",
    "\n",
    "It usually does not make sense to calculate Euclidean distance between two non-numeric categories (e.g., cookbooks and maps, in a bookstore). Therefore, before *k*-NN can be applied, categorical variables must be converted to binary dummies. In contrast to the situation with statistical models such as regression, all *m* binaries should be created and used with *k*-NN. While mathematically this is redundant, since *m* - 1 dummies contain the same information as *m* dummies, this redundant information does not create the multicollinearity problems that it does for linear models. Moreover, in *k*-NN the use of *m* - 1 dummies can yield different classifications than the use of *m* dummies, and lead to an imbalance in the contribution of the different categories to the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
