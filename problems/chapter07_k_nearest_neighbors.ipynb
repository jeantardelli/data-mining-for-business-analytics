{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a005a5",
   "metadata": {},
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ab4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from dmutils import classification_summary\n",
    "from dmutils import regression_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f54c2b",
   "metadata": {},
   "source": [
    "**1. Calculating Distance with Categorical Predictors.**\n",
    "\n",
    "This exercise with a tiny dataset illustrates the calculation of Euclidean distance, and the creation of binary\n",
    "dummies. The online education company Statistics.com segments its customers and prospects into three main categories: IT professionals (IT), statisticians (Stat), and other (Other). It also tracks, for each customer, the number of years since first contact (years). Consider the following customers; information about whether they have taken a course or not (the outcome to be predicted) is included:\n",
    "\n",
    "    Customer 1: Stat, 1 year, did not take course\n",
    "    Customer 2: Other, 1.1 year, took course\n",
    "\n",
    "**a.** Consider now the following new prospect:\n",
    "\n",
    "    Prospect 1: IT, 1 year\n",
    "\n",
    "Using the above information on the two customers and one prospect, create one dataset for all three with the categorical predictor variable transformed into 2 binaries, and a similar dataset with the categorical predictor variable transformed into 3 binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfaca762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Stat</th>\n",
       "      <th>years_since_first_contact</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  Stat  years_since_first_contact  course\n",
       "0   0     1                        1.0     0.0\n",
       "1   0     0                        1.1     1.0\n",
       "2   1     0                        1.0     NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset for all three customers with the categorical predictor (category)\n",
    "# transformed into 2 binaries\n",
    "tiny_two_cat_dummies_df = pd.DataFrame({\"IT\": [0, 0, 1], \"Stat\": [1, 0, 0],\n",
    "                                        \"years_since_first_contact\": [1, 1.1, 1],\n",
    "                                        \"course\": [0, 1, None]})\n",
    "tiny_two_cat_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f555d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Other</th>\n",
       "      <th>years_since_first_contact</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  Stat  Other  years_since_first_contact  course\n",
       "0   0     1      0                        1.0     0.0\n",
       "1   0     0      1                        1.1     1.0\n",
       "2   1     0      0                        1.0     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset for all three customers with the categorical predictor (category)\n",
    "# transformed into 3 binaries\n",
    "tiny_all_cat_dummies_df = pd.DataFrame({\"IT\": [0, 0, 1], \"Stat\": [1, 0, 0], \n",
    "                                        \"Other\": [0, 1, 0], \"years_since_first_contact\": [1, 1.1, 1],\n",
    "                                        \"course\": [0, 1, None]})\n",
    "tiny_all_cat_dummies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270110a",
   "metadata": {},
   "source": [
    "**b.** For each derived dataset, calculate the Euclidean distance between the prospect and each of the other two customers. (Note: While it is typical to normalize data for k-NN, this is not an iron-clad rule and you may proceed here without normalization.)\n",
    "\n",
    "- Two categorical dummies (IT/Stat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a56a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_1</th>\n",
       "      <th>customer_2</th>\n",
       "      <th>customer_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_2</th>\n",
       "      <td>1.004988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_3</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            customer_1  customer_2  customer_3\n",
       "customer_1    0.000000    1.004988    1.414214\n",
       "customer_2    1.004988    0.000000    1.004988\n",
       "customer_3    1.414214    1.004988    0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"IT\", \"Stat\", \"years_since_first_contact\"]\n",
    "pd.DataFrame(euclidean_distances(tiny_two_cat_dummies_df[predictors],\n",
    "                                 tiny_two_cat_dummies_df[predictors]),\n",
    "             columns=[\"customer_1\", \"customer_2\", \"customer_3\"],\n",
    "             index=[\"customer_1\", \"customer_2\", \"customer_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97daa",
   "metadata": {},
   "source": [
    "- Three categorical dummies (IT/Stat/Other):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d98c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_1</th>\n",
       "      <th>customer_2</th>\n",
       "      <th>customer_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_2</th>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_3</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            customer_1  customer_2  customer_3\n",
       "customer_1    0.000000    1.417745    1.414214\n",
       "customer_2    1.417745    0.000000    1.417745\n",
       "customer_3    1.414214    1.417745    0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"IT\", \"Stat\", \"Other\", \"years_since_first_contact\"]\n",
    "\n",
    "pd.DataFrame(euclidean_distances(tiny_all_cat_dummies_df[predictors],\n",
    "                                 tiny_all_cat_dummies_df[predictors]),\n",
    "             columns=[\"customer_1\", \"customer_2\", \"customer_3\"],\n",
    "             index=[\"customer_1\", \"customer_2\", \"customer_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732c44b",
   "metadata": {},
   "source": [
    "We can already see the effect of using two/three dummy variables. For the two dummy variables dataset, the `customer_3` is nearer to `customer_2` than to `customer_1`. This happens because the variable `years_since_first_contact` are the same for the both customers. For the three dummy variables, we still see that the `customer_3` are nearer to `customer_1` than to `customer_2` though the distances are very close between all customers. This happens because the `Other` variable helps to discriminate each of the customers.\n",
    "\n",
    "In contrast to the situation with statistical models such as regression, all *m* binaries should be created and\n",
    "used with *k*-NN. While mathematically this is redundant, since *m* - 1 dummies contain the same information as *m* dummies, this redundant information does not create the multicollinearity problems that it does for linear models. Moreover, in *k*-NN the use of *m* - 1 dummies can yield different classifications than the use of *m* dummies, and lead to an imbalance in the contribution of the different categories to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b71c1",
   "metadata": {},
   "source": [
    "**c.** Using k-NN with k = 1, classify the prospect as taking or not taking a course using each of the two derived datasets. Does it make a difference whether you use two or three dummies?\n",
    "\n",
    "- Two dummies variables (IT/Stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9898679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Stat</th>\n",
       "      <th>years_since_first_contact</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  Stat  years_since_first_contact  course\n",
       "1   0     0                        1.1     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"IT\", \"Stat\", \"years_since_first_contact\"]\n",
    "\n",
    "# user NearestNeighbors from scikit-learn to compute knn\n",
    "knn = NearestNeighbors(n_neighbors=1)\n",
    "knn.fit(tiny_two_cat_dummies_df.loc[:1, predictors])\n",
    "\n",
    "new_customer = pd.DataFrame({\"IT\": [1], \"Stat\": [0],\n",
    "                             \"years_since_first_contact\": [1]})\n",
    "\n",
    "distances, indices = knn.kneighbors(new_customer)\n",
    "\n",
    "# indices is a list of lists, we are only interested in the first element\n",
    "tiny_two_cat_dummies_df.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c14e7",
   "metadata": {},
   "source": [
    "- Three dummies variable(IT/Stat/Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b8fd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Other</th>\n",
       "      <th>years_since_first_contact</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  Stat  Other  years_since_first_contact  course\n",
       "1   0     0      1                        1.1     1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"IT\", \"Stat\", \"Other\", \"years_since_first_contact\"]\n",
    "\n",
    "# user NearestNeighbors from scikit-learn to compute knn\n",
    "knn = NearestNeighbors(n_neighbors=1)\n",
    "knn.fit(tiny_all_cat_dummies_df.loc[:1, predictors])\n",
    "\n",
    "new_customer = pd.DataFrame({\"IT\": [1], \"Stat\": [0], \"Other\": [1],\n",
    "                             \"years_since_first_contact\": [1]})\n",
    "\n",
    "distances, indices = knn.kneighbors(new_customer)\n",
    "\n",
    "# indices is a list of lists, we are only interested in the first element\n",
    "tiny_all_cat_dummies_df.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cb005",
   "metadata": {},
   "source": [
    "If we use *k* = 1, the nearest customer is the one that took the course for both variables. Therefore, for this specific example there was no difference on using two or three categorical variable. Therefore, as indicated in the previous item (**b**), this redundant information does not create the multicollinearity problems that it does for linear models. Moreover, in *k*-NN the use of *m* - 1 dummies can yield different classifications than the use of *m* dummies, and lead to an imbalance in the contribution of the different categories to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f98155",
   "metadata": {},
   "source": [
    "**2. Personal Loan Acceptance.** Universal Bank is a relatively young bank growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business. In particular, it wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors).\n",
    "\n",
    "A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal is to use *k*-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign.\n",
    "\n",
    "The file `UniversalBank.csv` contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (=9.6%) accepted the personal loan that was offered to them in the earlier campaign.\n",
    "\n",
    "Partition the data into training (60%) and validation (40%) sets.\n",
    "\n",
    "**a.** Consider the following customer:\n",
    "    \n",
    "    Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0,\n",
    "    Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CDAccount = 0,\n",
    "    Online = 1, and Credit Card = 1.\n",
    "    \n",
    "Perform a *k*-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371ac3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df = pd.read_csv(\"../datasets/UniversalBank.csv\")\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1356735d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zAge</th>\n",
       "      <th>zExperience</th>\n",
       "      <th>zIncome</th>\n",
       "      <th>zFamily</th>\n",
       "      <th>zCCAvg</th>\n",
       "      <th>zEducation_1</th>\n",
       "      <th>zEducation_2</th>\n",
       "      <th>zEducation_3</th>\n",
       "      <th>zMortgage</th>\n",
       "      <th>zSecurities Account</th>\n",
       "      <th>zCD Account</th>\n",
       "      <th>zOnline</th>\n",
       "      <th>zCreditCard</th>\n",
       "      <th>Personal Loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>-0.893355</td>\n",
       "      <td>-0.787261</td>\n",
       "      <td>0.199307</td>\n",
       "      <td>-0.340587</td>\n",
       "      <td>-0.122566</td>\n",
       "      <td>-0.856799</td>\n",
       "      <td>1.587806</td>\n",
       "      <td>-0.643242</td>\n",
       "      <td>-0.547625</td>\n",
       "      <td>-0.346151</td>\n",
       "      <td>-0.248891</td>\n",
       "      <td>0.806328</td>\n",
       "      <td>1.549632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          zAge  zExperience   zIncome   zFamily    zCCAvg  zEducation_1  \\\n",
       "4034 -0.893355    -0.787261  0.199307 -0.340587 -0.122566     -0.856799   \n",
       "\n",
       "      zEducation_2  zEducation_3  zMortgage  zSecurities Account  zCD Account  \\\n",
       "4034      1.587806     -0.643242  -0.547625            -0.346151    -0.248891   \n",
       "\n",
       "       zOnline  zCreditCard  Personal Loan  \n",
       "4034  0.806328     1.549632              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define predictors and the outcome for this problem\n",
    "predictors = [\"Age\", \"Experience\", \"Income\", \"Family\", \"CCAvg\", \"Education\", \"Mortgage\",\n",
    "              \"Securities Account\", \"CD Account\", \"Online\", \"CreditCard\"]\n",
    "outcome = \"Personal Loan\"\n",
    "\n",
    "# before k-NN, we will convert 'Education' to binary dummies.\n",
    "# 'Family' remains unchanged\n",
    "customer_df = pd.get_dummies(customer_df, columns=[\"Education\"], prefix_sep=\"_\")\n",
    "\n",
    "# update predictors to include the new dummy variables\n",
    "predictors = [\"Age\", \"Experience\", \"Income\", \"Family\", \"CCAvg\", \"Education_1\",\n",
    "              \"Education_2\", \"Education_3\", \"Mortgage\",\n",
    "              \"Securities Account\", \"CD Account\", \"Online\", \"CreditCard\"]\n",
    "\n",
    "# partition the data into training 60% and validation 40% sets\n",
    "train_data, valid_data = train_test_split(customer_df, test_size=0.4,\n",
    "                                          random_state=26)\n",
    "\n",
    "# equalize the scales that the various predictors have(standardization)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data[predictors])\n",
    "\n",
    "# transform the full dataset\n",
    "customer_norm = pd.concat([pd.DataFrame(scaler.transform(customer_df[predictors]),\n",
    "                                        columns=[\"z\"+col for col in predictors]),\n",
    "                           customer_df[outcome]], axis=1)\n",
    "\n",
    "train_norm = customer_norm.iloc[train_data.index]\n",
    "valid_norm = customer_norm.iloc[valid_data.index]\n",
    "\n",
    "# new customer\n",
    "new_customer = pd.DataFrame({\"Age\": [40], \"Experience\": [10], \"Income\": [84], \"Family\": [2],\n",
    "                             \"CCAvg\": [2], \"Education_1\": [0], \"Education_2\": [1],\n",
    "                             \"Education_3\": [0], \"Mortgage\": [0], \"Securities Account\": [0],\n",
    "                             \"CDAccount\": [0], \"Online\": [1], \"Credit Card\": [1]})\n",
    "new_customer_norm = pd.DataFrame(scaler.transform(new_customer),\n",
    "                                 columns=[\"z\"+col for col in predictors])\n",
    "\n",
    "# use NearestNeighbors from scikit-learn to compute knn\n",
    "# using all the dataset (training + validation sets) here!\n",
    "knn = NearestNeighbors(n_neighbors=1)\n",
    "knn.fit(customer_norm.iloc[:, 0:-1])\n",
    "\n",
    "distances, indices = knn.kneighbors(new_customer_norm)\n",
    "\n",
    "# indices is a list of lists, we are only interested in the first element\n",
    "customer_norm.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae434ae",
   "metadata": {},
   "source": [
    "Since the closest customer did not accepted the loan (=0), we can estimate for the new customer a probability of 1 of being an non-borrower (and 0 for being a borrower). Using a simple majority rule is equivalent to setting the cutoff value to 0.5. In the above results, we see that the software assigned class non-borrower to this record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567335b6",
   "metadata": {},
   "source": [
    "**b.** What is a choice of *k* that balances between overfitting and ignoring the predictor information?\n",
    "\n",
    "First, we need to remember that a balanced choice greatly depends on the nature of the data. The more complex and irregular the structure of the data, the lower the optimum value of *k*. Typically, values of *k* fall in the range of 1-20. We will use odd numbers to avoid ties.\n",
    "\n",
    "If we choose *k* = 1, we will classify in a way that is very sensitive to the local characteristics of the training data. On the other hand, if we choose a large value of *k*, such as *k* = 14, we would simply predict the most frequent class in the dataset in all cases.\n",
    "\n",
    "To find a balance, we examine the accuracy (of predictions in the validation set) that results from different choices of *k* between 1 and 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639293bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.9405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy\n",
       "0    1    0.9550\n",
       "1    2    0.9460\n",
       "2    3    0.9555\n",
       "3    4    0.9445\n",
       "4    5    0.9525\n",
       "5    6    0.9445\n",
       "6    7    0.9495\n",
       "7    8    0.9425\n",
       "8    9    0.9460\n",
       "9   10    0.9430\n",
       "10  11    0.9450\n",
       "11  12    0.9390\n",
       "12  13    0.9405\n",
       "13  14    0.9350"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_norm[[\"z\"+col for col in predictors]]\n",
    "train_y = train_norm[outcome]\n",
    "valid_X = valid_norm[[\"z\"+col for col in predictors]]\n",
    "valid_y = valid_norm[outcome]\n",
    "\n",
    "# Train a classifier for different values of k\n",
    "results = []\n",
    "for k in range(1, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k).fit(train_X, train_y)\n",
    "    results.append({\"k\": k,\n",
    "                    \"accuracy\": accuracy_score(valid_y, knn.predict(valid_X))})\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d62bd",
   "metadata": {},
   "source": [
    "Based on the above table, we would choose **k = 3** (though **k = 5** appears to be another option too), which maximizes our accuracy in the validation set. Note, however, that now the validation set is used as part of the training process (to set *k*) and does not reflect a\n",
    "true holdout set as before. Ideally, we would want a third test set to evaluate the performance of the method on data that it did not see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9aada",
   "metadata": {},
   "source": [
    "**c.** Show the confusion matrix for the validation data that results from using the best *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0eb5a",
   "metadata": {},
   "source": [
    "- k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea1f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9555)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1779    6\n",
      "     1   83  132\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3).fit(train_X, train_y)\n",
    "classification_summary(y_true=valid_y, y_pred=knn.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a8c0e",
   "metadata": {},
   "source": [
    "- k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a67b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9525)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1781    4\n",
      "     1   91  124\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5).fit(train_X, train_y)\n",
    "classification_summary(y_true=valid_y, y_pred=knn.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a938c6",
   "metadata": {},
   "source": [
    "**d.** Consider the following customer:\n",
    "\n",
    "    Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0,\n",
    "    Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0,\n",
    "    Online = 1 and Credit Card = 1.\n",
    "\n",
    "Classify the customer using the best *k*.\n",
    "\n",
    "Note: once *k* is chosen, we rerun the algorithm on the combined training and testing sets in order to generate classifications of new records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c3e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([[1., 0.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the same user created before :) \n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(customer_norm.iloc[:, 0:-1],\n",
    "                                              customer_norm.loc[:, \"Personal Loan\"])\n",
    "knn.predict(new_customer_norm), knn.predict_proba(new_customer_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d467ab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([[1., 0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5).fit(customer_norm.iloc[:, 0:-1],\n",
    "                                              customer_norm.loc[:, \"Personal Loan\"])\n",
    "knn.predict(new_customer_norm), knn.predict_proba(new_customer_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a9230",
   "metadata": {},
   "source": [
    "Using the best *k* (=3) the user was classified as a **non-borrower**. Also with *k* = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dafd87d",
   "metadata": {},
   "source": [
    "**e**. Repartition the data, this time into training, validation, and test sets (50%:30%:20%). Apply the *k*-NN method with the *k* chosen above. Compare the confusion matrix of the test set with that of the training and validation sets. Comment on the differences and their reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ca229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "************\n",
      "Confusion Matrix (Accuracy 0.9760)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2258    1\n",
      "     1   59  182\n",
      "\n",
      "Validation set\n",
      "**************\n",
      "Confusion Matrix (Accuracy 0.9553)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1343    6\n",
      "     1   61   90\n",
      "\n",
      "Test set\n",
      "********\n",
      "Confusion Matrix (Accuracy 0.9600)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 906   6\n",
      "     1  34  54\n"
     ]
    }
   ],
   "source": [
    "# using the customer_norm computed earlier\n",
    "# training: 50%\n",
    "# validation: 30% (0.5 * 0.6)\n",
    "# test: 20% (0.5 * 0.4)\n",
    "train_data, temp = train_test_split(customer_df, test_size=0.50, random_state=1)\n",
    "valid_data, test_data = train_test_split(temp, test_size=0.40, random_state=1)\n",
    "\n",
    "train_norm = customer_norm.iloc[train_data.index]\n",
    "valid_norm = customer_norm.iloc[valid_data.index]\n",
    "test_norm  = customer_norm.iloc[test_data.index]\n",
    "\n",
    "train_X = train_norm[[\"z\"+col for col in predictors]]\n",
    "train_y = train_norm[outcome]\n",
    "valid_X = valid_norm[[\"z\"+col for col in predictors]]\n",
    "valid_y = valid_norm[outcome]\n",
    "test_X  = test_norm[[\"z\"+col for col in predictors]]\n",
    "test_y  = test_norm[outcome]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(train_X, train_y)\n",
    "\n",
    "print(\"Training set\\n\" + \"*\" * 12)\n",
    "classification_summary(y_true=train_y, y_pred=knn.predict(train_X))\n",
    "print(\"\\nValidation set\\n\" + \"*\" * 14)\n",
    "classification_summary(y_true=valid_y, y_pred=knn.predict(valid_X))\n",
    "print(\"\\nTest set\\n\" + \"*\" * 8)\n",
    "classification_summary(y_true=test_y, y_pred=knn.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747a7e7",
   "metadata": {},
   "source": [
    "Based on the training, validation, and test matrices we can see a steady increase in the percentage error from training set and validation/test sets. As the model is being fit on the training data it would make intuitive sense that the classifications are most accurate on it rather than validation/test datasets. \n",
    "\n",
    "We can see also that there does not appear to be overfitting due to the minimal error discrepancies among all three matrices, and specially between validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281d19e",
   "metadata": {},
   "source": [
    "**3. Predicting Housing Median Prices.** The file `BostonHousing.csv` contains information on over 500 census tracts in Boston, where for each tract multiple variables are recorded. The last column (`CAT.MEDV`) was derived from `MEDV`, such that it obtains the value 1 if `MEDV` > 30 and 0 otherwise. Consider the goal of predicting the median value (`MEDV`) of a tract, given the information in the first 12 columns.\n",
    "\n",
    "Partition the data into training (60%) and validation (40%) sets.\n",
    "\n",
    "**a.** Perform a *k*-NN prediction with all 12 predictors (ignore the `CAT.MEDV` column), trying values of *k* from 1 to 5. Make sure to normalize the data. What is the best *k*? What does it mean?\n",
    "\n",
    "The idea of *k*-NN can readily be extended to predicting a continuous value (as is our aim with multiple linear regression models). The first step of determining neighbors by computing distances remains unchanged. The second step, where a majority vote of the neighbors is used to determine class, is modified such that we take the average outcome value of the *k*-nearest neighbors to determine the prediction. Often, this average is a weighted average, with the weight decreasing with increasing distance from the point at which the prediction is required. In `scikit-learn`, we can use `KNeighborsRegressor` to compute *k*-NN numerical predictions for the validation set.\n",
    "\n",
    "Another modification is in the error metric used for determining the \"best k\". Rather than the overall error rate used in classification, RMSE (root-mean-squared error) or another prediction error metric should be used in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ecbead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  CAT. MEDV  \n",
       "0   4.98  24.0          0  \n",
       "1   9.14  21.6          0  \n",
       "2   4.03  34.7          1  \n",
       "3   2.94  33.4          1  \n",
       "4   5.33  36.2          1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv(\"../datasets/BostonHousing.csv\")\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77490a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>mean_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.391626</td>\n",
       "      <td>5.273145</td>\n",
       "      <td>3.350246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.306443</td>\n",
       "      <td>4.581736</td>\n",
       "      <td>2.898078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.305676</td>\n",
       "      <td>4.517485</td>\n",
       "      <td>2.823457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.338562</td>\n",
       "      <td>4.706598</td>\n",
       "      <td>2.890872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.481599</td>\n",
       "      <td>4.770011</td>\n",
       "      <td>2.870980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  mean_error      rmse       mae\n",
       "0  1    0.391626  5.273145  3.350246\n",
       "1  2    0.306443  4.581736  2.898078\n",
       "2  3    0.305676  4.517485  2.823457\n",
       "3  4    0.338562  4.706598  2.890872\n",
       "4  5    0.481599  4.770011  2.870980"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define predictors and the outcome for this problem\n",
    "predictors = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\",\n",
    "              \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"LSTAT\"]\n",
    "outcome = \"MEDV\"\n",
    "\n",
    "# partition the data into training 60% and validation 40% sets\n",
    "train_data, valid_data = train_test_split(housing_df, test_size=0.4,\n",
    "                                          random_state=26)\n",
    "\n",
    "# equalize the scales that the various predictors have(standardization)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data[predictors])\n",
    "\n",
    "# transform the full dataset\n",
    "housing_norm = pd.concat([pd.DataFrame(scaler.transform(housing_df[predictors]),\n",
    "                                       columns=[\"z\"+col for col in predictors]),\n",
    "                          housing_df[outcome]], axis=1)\n",
    "\n",
    "train_norm = housing_norm.iloc[train_data.index]\n",
    "valid_norm = housing_norm.iloc[valid_data.index]\n",
    "\n",
    "# Perform a k-NN prediction with all 12 predictors\n",
    "# trying values of k from 1 to 5\n",
    "train_X = train_norm[[\"z\"+col for col in predictors]]\n",
    "train_y = train_norm[outcome]\n",
    "valid_X = valid_norm[[\"z\"+col for col in predictors]]\n",
    "valid_y = valid_norm[outcome]\n",
    "\n",
    "# Train a classifier for different values of k\n",
    "# Using weighted average\n",
    "results = []\n",
    "for k in range(1, 6):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights=\"distance\").fit(train_X, train_y)\n",
    "    y_pred = knn.predict(valid_X)\n",
    "    y_res = valid_y - y_pred\n",
    "\n",
    "    results.append({\"k\": k,\n",
    "                    \"mean_error\": sum(y_res) / len(y_res),\n",
    "                    \"rmse\": math.sqrt(mean_squared_error(valid_y, y_pred)),\n",
    "                    \"mae\": sum(abs(y_res)) / len(y_res)})\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee58bc",
   "metadata": {},
   "source": [
    "Using the RMSE (root mean squared errors) as the *k* decision driver, the best *k* is 4. We choose 4 as a way to minimize the errors found in the validation set. Note, however, that now the validation set is used as part of the training process (to set *k*) and does not reflect a true holdout set as before.\n",
    "\n",
    "Note also that performance on validation data may be overly optimistic when it comes to predicting performance on data that have not been exposed to the model at all. This is because when the validation data are used to select a final model among a set of model, we are selecting based on how well the model performs with those data and therefore may be incorporating some of the random idiosyncrasies (bias) of the validation data into the judgment about the best model. \n",
    "\n",
    "The model still may be the best for the validation data among those considered, but it will probably not do as well with the unseen data. Therefore, it is useful to evaluate the chosen model on a new test set to get a sense of how well it will perform on new data. In addition, one must consider practical issues such as costs of collecting variables, error-proneness, and model complexity in the selection of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e256b",
   "metadata": {},
   "source": [
    "**b.** Predict the `MEDV` for a tract with the following information, using the best *k*:\n",
    "\n",
    "    CRIM: 0.2\n",
    "    ZN: 0\n",
    "    INDUS: 7\n",
    "    CHAS: 0\n",
    "    NOX: 0.538\n",
    "    RM: 6\n",
    "    AGE: 62\n",
    "    DIS: 4.7\n",
    "    RAD: 4\n",
    "    TAX: 307\n",
    "    PTRATIO: 21\n",
    "    LSTAT: 10\n",
    "\n",
    "Once *k* is chosen, we rerun the algorithm on the combined training and testing sets in order to generate classifications of new records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ed8db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.61274142])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new house to be predicted. Before predicting the MEDV we normalize it\n",
    "new_house = pd.DataFrame({\"CRIM\": [0.2], \"ZN\": [0], \"INDUS\": [7], \"CHAS\": [0],\n",
    "                          \"NOX\": [0.538], \"RM\": [6], \"AGE\": [62], \"DIS\": [4.7],\n",
    "                          \"RAD\": [4], \"TAX\": [307], \"PTRATIO\": [21], \"LSTAT\": [10]})\n",
    "new_house_norm = pd.DataFrame(scaler.transform(new_house),\n",
    "                              columns=[\"z\"+col for col in predictors])\n",
    "\n",
    "# retrain the knn using the best k and all data\n",
    "knn = KNeighborsRegressor(n_neighbors=4, weights=\"distance\").fit(housing_norm[[\"z\"+col for col in predictors]],\n",
    "                                                                 housing_norm[outcome])\n",
    "knn.predict(new_house_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc5be2",
   "metadata": {},
   "source": [
    "The new house has a predicted value of 19.6 (in \\\\$1000s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466f3fa",
   "metadata": {},
   "source": [
    "**c.** If we used the above *k*-NN algorithm to score the training data, what would be the error of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee6a7c",
   "metadata": {},
   "source": [
    "It would be zero or near zero. This happens because the best *k* was selected from a model built using such dataset. Therefore, we have used the same data for fitting the classification functions and for estimating the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b40f2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>mean_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  mean_error  rmse  mae\n",
       "0  4         0.0   0.0  0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the previous trained model (all data, k=5) \n",
    "y_pred = knn.predict(train_X)\n",
    "y_res = train_y - y_pred\n",
    "\n",
    "results = {\"k\": 4,\n",
    "           \"mean_error\": sum(y_res) / len(y_res),\n",
    "           \"rmse\": math.sqrt(mean_squared_error(train_y, y_pred)),\n",
    "           \"mae\": sum(abs(y_res)) / len(y_res)}\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results, index=[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fbe8f",
   "metadata": {},
   "source": [
    "**d.** Why is the validation data error overly optimistic compared to the error rate when applying this *k*-NN predictor to new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba0c3",
   "metadata": {},
   "source": [
    "When we use the validation data to assess multiple models and then choose the model that performs best with the validation data, we again encounter another (lesser) facet of the overfitting problem - chance aspects of the validation data that happen to match the chosen model better than they match other models. In other words, by using the validation data to choose one of several models, the performance of the chosen model on the validation data will be overly optimistic.\n",
    "\n",
    "In other words, chances are that the training/validation sets can be biased, so cross-validation would give a better approximation in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c23c5f",
   "metadata": {},
   "source": [
    "**e.** If the purpose is to predict `MEDV` for several thousands of new tracts, what would be the disadvantage of using *k*-NN prediction? List the operations that the algorithm goes through in order to produce each prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436de6d",
   "metadata": {},
   "source": [
    "The disadvantage of the *k*-NN in this case would be it's laziness characteristic meaning that it would take too much time to predict all the cases. \n",
    "\n",
    "Basically, the algorithm would need to perform the following operations repeatedly for each case to predict the `MEDV` value for them: \n",
    "\n",
    "- Normalize the data of each new variable for each case based on the mean and standard deviation in training data set; \n",
    "- Calculate the distance of this case from all the training data;\n",
    "- Sorting the new data based on the calculated distances;\n",
    "- Use the majority rule on the first *k* nearest neighbors to predict the new case; \n",
    "\n",
    "And as mentioned this process would be repeated for each of the thousands of new cases which would be computationally expensive and time consuming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
